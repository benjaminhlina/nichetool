---
title: "Using {nichetools} with SIBER"
author: Benjamin L. Hlina
date: "Updated: `r Sys.Date()`"
output: rmarkdown::html_vignette

vignette: >
  %\VignetteIndexEntry{Using {nichetools} with SIBER}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

### Our Objectives

The purpose of this vignette is to use [{SIBER}](https://cran.r-project.org/package=SIBER) and [{nichetools}](https://benjaminhlina.github.io/nichetools/) to extract and then visualize estimates of trophic niche size and similarities and Layman community metrics for multiple freshwater fish using [{ggplot2}](https://ggplot2.tidyverse.org/). 

This vignette can be used for additional purposes including estimating niche size and similarities among different groups of aquatic and/or terrestrial species. Furthermore, niche size and similarities for different behaviours exhibited within a population can be made using behavioural data generated from acoustic telemetry (e.g., differences in habitat occupancy).

### Bring in trophic data
First we will load the necessary packages to preform the analysis and visualization. We will use [{SIBER}](https://cran.r-project.org/package=SIBER) and [{nichetools}](https://benjaminhlina.github.io/nichetools/) to preform the analysis. We will use [{bayestestR}](https://easystats.github.io/bayestestR/) to calcuate and extract etis and medians for posterior distubtions that we want to plot. We will use [{dplyr}](https://dplyr.tidyverse.org/), [{tidyr}](https://tidyr.tidyverse.org/), and [{purrr}](https://purrr.tidyverse.org/) to manipulate data and iterate processes. Lastly, we will use [{ggplot2}](https://ggplot2.tidyverse.org/), [{ggtext}](https://wilkelab.org/ggtext/), and [{patchwork}](https://patchwork.data-imaginist.com/) to plot, add labels, and arrange plots.

I will add that many of the `{dplyr}` and `{tidyr}` functions and processes can be replaced using [{data.table}](https://CRAN.R-project.org/package=data.table) which is great when working with large data sets.

We will first load the packages that were just mentioned 
```{r, message=FALSE}
{
  library(bayestestR)
  library(dplyr)
  library(ggplot2)
  library(ggdist)
  library(ggtext)
  library(nichetools)
  library(patchwork)
  library(purrr)
  library(SIBER)
  library(tidyr)
  library(viridis)
}
```
For the purpose of the vignette we will be using the `demo.siber.data.2` data frame that is available within `{SIBER}`. We will first look at the structure of this data frame using the `{dplyr}` function `glimpse()` For your purposes you will need to replace this with your data frame either by loading a csv, rds, or qs. You can do this multiple ways, I prefer using `readr::read_csv()` but base R's `read.csv()` works perfectly fine. Note, `{SIBER}` functions do not take `tibbles` or `data.tables` so you will have to convert either to `data.frame` class prior to running funcgtions in `{SIBER}`. 

```{r}
glimpse(demo.siber.data.2)
```

You will notice that the community and group column are character strings that are the actual names of the communities and groups. Similarly, you will likely have names associated with the communities and groups you are working with, instead of 1, 2, 3 ect. I advise changing them into factors thus allow you to know the order for each column. The reason why this is important, is that functions in `{SIBER}` use `for` loops based on the indexing of the `SiberObject`. If this order does not match up you can have issues with the names of the communities and groups you are working with.

So first, change these into factors, then preserve the column and create an id column that is the numerical order that will become the community and group names fed to `createSiberObject()`. 

```{r}
demo.siber.data.2 <- demo.siber.data.2 %>%
  mutate(
    group = factor(group), 
    community = factor(community), 
    group_id = as.numeric(group) %>% 
      as.character(),
    community_id = as.numeric(community) %>%
      as.character()
  ) %>% 
  rename(
    group_name = group,
    community_name = community,
    group = group_id,
    community = community_id
  )

glimpse(demo.siber.data.2)
```

After we have done this, we are going to create two data frames that are the names of our communities and groups with their associated id values. We will use these data frames later on to join up the actual names, allowing us to know what estimates belong to which communities and groups, preserving the names that we have originally assigned them. Again this is done because it is unlikely you will have communities and groups named 1, 2, 3 ect. and instead will have actual names. 

```{r}
# ---- create name with group and community data frame ----
cg_names <- demo.siber.data.2 %>%
  distinct(group,
           community, 
           group_name, 
           community_name) %>%
  
  arrange(community, group)

# ---- create community names data frame ---- 
c_names <- demo.siber.data.2 %>% 
  distinct(community, 
           community_name) %>%
  arrange(community)
```
We will then plot our biplot to confirm we have the correct structure. 

```{r}
#| out-width: 100%
ggplot(data = demo.siber.data.2, aes(x = iso1, y = iso2,
                                     colour = group_name)) +
  geom_point() +
  facet_wrap(~ community_name) + 
  scale_colour_viridis_d(option = "A", begin = 0.25, end = 0.85,
                         name = "Groups", alpha = 0.75) + 
  theme_bw(
    base_size = 15
  ) + 
  theme(
    strip.background = element_blank(),
    panel.grid = element_blank(), 
    legend.position = "inside",
    legend.position.inside = c(0.65, 0.75)
  ) + 
  labs(
    x = expression(paste(delta^13,"C (‰)")), 
    y = expression(paste(delta^15,"N (‰)")) 
  )
```

Next we will grab the isotopes we need and the community and group ids, and we will  rename them to `community` and `group`. This is important as `creatSiberObject()` will 1) only take the following order with the following names `iso1`, `iso2`, `group`, and `community` and 2) we will transform this `tibble` into a `data.frame` as `{SIBER}` will only work with `data.frame`. In this case we were using tibbles but we could also be working with `data.table` and will need to do the same thing. 

```{r}
demo_siber_data <- demo.siber.data.2 %>% 
  dplyr::select(iso1, iso2, group, community) %>%
  arrange(community, group) %>% 
  as.data.frame() 
```

### Convert to {SIBER} object

We will convert to a `{SIBER}` object, once we have the `{SIBER}` object we can start our analysis. 

```{r}
siber_example <- createSiberObject(demo_siber_data)
```

Now that we have converted this to a `{SIBER}` object we can start doing some analysis using a Bayesian framework. The data and metrics generated through this analysis by `{SIBER}` can be extracted using functions in  `{nichetools}`. 

### Bayesian Ellipse Analysis 

We first need to set the parameters to run the model 

```{r}
# options for running jags
parms <- list()
parms$n.iter <- 2 * 10^4   # number of iterations to run the model for
parms$n.burnin <- 1 * 10^3 # discard the first set of values
parms$n.thin <- 10     # thin the posterior by this many
parms$n.chains <- 2        # run this many chains
```

Next we need to define the priors for each parameter of the model. This includes fitting the ellipses using an Inverse Wishart prior on the covariance matrix $\Sigma$ , and a vague normal prior on the means ($\mu$).

```{r}
# fit the ellipses which uses an Inverse Wishart prior on the 
# covariance matrix Sigma, and a vague normal prior on the 
# means.
priors <- list()
priors$R <- 1 * diag(2)
priors$k <- 2
priors$tau.mu <- 1.0E-3
```

We will now run the model using the function `siberMVN()`. 

```{r, message=FALSE, results='hide'}
ellipses_posterior <- siberMVN(siber_example, parms, priors)
```

### Extract posterior distributions for μ and Σ

We will first extract posterior distribution for $\mu$ using `extract_mu()` in `{nichetools}`. We will need to set the argument `pkg` to `"SIBER"` and because of what we are going to do with the data afterwards. We are going to set `data_format` to `"wide"`. This argument takes `"long"` or `"wide"` which dictates whether the data object returned is in wide or long format. We will also use the function `seperate_wider_delim()` from {tidyr} to seperate the community and groups names as they are joined by a `.`. We then will use `left_join()` and the `cg_names` data frame we created above to add in the correct community and group names. 

```{r, message = FALSE}
df_mu <- extract_mu(ellipses_posterior, pkg = "SIBER", 
                    data_format = "wide") %>%
  separate_wider_delim(sample_name, cols_remove = FALSE,
                       delim = ".", names = c("community",
                                              "group")) %>%
  left_join(cg_names)
```

We can confirm that the posterior estimates of $\mu$ are correct by plotting them with {ggplot2} 

```{r}
#| out-width: 100%
ggplot() +
  geom_point(data = df_mu, aes(x = d13c, y = d15n,
                               colour = group_name)) +
  geom_point(data = demo.siber.data.2, aes(x = iso1, y = iso2,
                                           colour = group_name)) +
  facet_wrap( ~ community_name) + 
  scale_colour_viridis_d(option = "A", begin = 0.25, end = 0.85,
                         name = "Groups", alpha = 0.75) + 
  theme_bw(
    base_size = 15
  ) + 
  theme(
    strip.background = element_blank(),
    panel.grid = element_blank(), 
    legend.position = "inside",
    legend.position.inside = c(0.65, 0.75)
  ) + 
  labs(
    x = expression(paste(delta^13,"C (‰)")), 
    y = expression(paste(delta^15,"N (‰)")) 
  )
```

Notice the density of points in the center of the raw data with the corresponding colours. This density of points are the posterior estimates from the model for $\mu$ and are an indication that the model is iterating over the groups and communities correctly.  

We are also going to extract $\mu$ in long format for creating ellipse, as the functions that create ellipse need the data frame of $\mu$ to be in long format. 

```{r, message=FALSE}
df_mu_long <- extract_mu(ellipses_posterior, pkg = "SIBER") %>% 
  separate_wider_delim(sample_name, cols_remove = FALSE,
                       delim = ".", names = c("community",
                                              "group")) %>%
  left_join(cg_names)
```

Next we are going to extract posterior estimates of $\Sigma$ using `extract_sigma()`. 

```{r}
df_sigma <- extract_sigma(ellipses_posterior, pkg = "SIBER")
```

Lastly, we are going to feed each $\mu$ and $\Sigma$ estimate to `niche_ellipse()` to estimate each ellipse. There are few things to know about this function and they include the following: 1) it will randomly sample 10 ellipse from the total posterior disturbitons of $\mu$ and $\Sigma$, this seems quite standard, however you can adjust the number of samples by changing the argument `n`. 2) to make the function consistently randomly sample the same set you will need to set `set_seed` to a numerical value. If this is not set then it will randomly sample a different set of 10 ellipses every time. 3) if you would like the function to not randomly sample set the argument `random` to `FALSE`. 4) by default it will tell you how long it takes to generate the ellipse and will have progress bars at each step. If you want to turn this off set `message` to `FALSE`. 5) if you are wanting to change the confidence level of the ellipse you can do so using the argument `p_ell`. This value is bound between 0 and 1. 

```{r, message = FALSE}
df_el <- niche_ellipse(dat_mu = df_mu_long,
                       dat_sigma = df_sigma, 
                       set_seed = 4, n = 20) %>%
  separate_wider_delim(sample_name, cols_remove = FALSE,
                       delim = ".", names = c("community",
                                              "group")) %>%
  left_join(cg_names)
```

Now that we have the ellipses created we can plot them

```{r}
#| out-width: 100%
ggplot(data = df_el, 
       aes(x = d13c, y = d15n, 
           group = interaction(sample_number, 
                               sample_name), 
           colour = group_name)) + 
  geom_polygon(linewidth = 0.5, fill = NA) + 
  facet_wrap( ~ community_name) + 
  scale_colour_viridis_d(option = "A", begin = 0.25, end = 0.85,
                         name = "Groups", alpha = 0.75) + 
  theme_bw(
    base_size = 15
  ) + 
  theme(
    strip.background = element_blank(),
    panel.grid = element_blank(), 
    legend.position = "inside",
    legend.background = element_blank(), 
    legend.position.inside = c(0.65, 0.75)
  ) + 
  labs(
    x = expression(paste(delta^13,"C (‰)")), 
    y = expression(paste(delta^15,"N (‰)")) 
  )
```

### Extract Niche Size 

We can use `siberEllipses()` from {SIBER} to estimate niche size for each posterior sample for each community and group.  

```{r}
sea_b <- siberEllipses(corrected.posteriors = ellipses_posterior)
```

Next using `extract_niche_size()` from {nichetools} we can extract niche size which will also add in the correct names for the community and groups we are working with. 

```{r}
seb_convert <- extract_niche_size(data = sea_b,
                                  pkg = "SIBER",
                                  community_df = cg_names)
```

We will also extract the parametric estimate for niche size using `groupMetricsML()` from {SIBER}. 

```{r}
group_ml <- groupMetricsML(siber_example)
```

We can convert the output of this function into something we can work with using `extract_group_metrics()`. 

```{r}
group_convert <- extract_group_metrics(data = group_ml,
                                       community_df = cg_names)
```

The object returned will have maximum-liklihod estimates for standard ellipse area (SEA), central standard ellipse area (SEAc), and total area (TA). For plotting niche size we will use the SEAc. 

```{r}
sea_c <- group_convert %>% 
  filter(metric == "SEAc")
```


Lastly, we can visualize the extracted niche sizes using {ggplot2}. 

```{r}
#| out-width: 100%
ggplot() +
  geom_violin(data = seb_convert, aes(x = community_name,
                                      y = sea,
                                      fill = group_name)) + 
  scale_fill_viridis_d(option = "A", begin = 0.25, end = 0.85,
                       name = "Groups", alpha = 0.75) + 
  geom_point(data = sea_c, aes(x = community_name, 
                               y = est, 
                               group = group_name,
  ), 
  size = 2.5,
  fill = "white",
  shape = 21,
  position = position_dodge(width = 0.9)) +
  theme_bw(
    base_size = 15
  ) + 
  theme(
    strip.background = element_blank(),
    panel.grid = element_blank(), 
    legend.position = "inside",
    legend.background = element_blank(), 
    legend.position.inside = c(0.85, 0.8)
  ) + 
  labs(
    x = "Communities", 
    y = expression(paste("Niche Size p(", "‰"^2, "| x)"))
  )
```


### Niche Similarties 



### Bayesian Estimates of Layman's Community Metrics

First I highly recommend reading [Post et al. 2007](https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1890/0012-9658%282007%2988%5B42%3ACSIRPF%5D2.0.CO%3B2) to understand the following six community metrics, that we are going to estimate using a Bayesian framework. 

To create Bayesian estiamtes of Layman's community metrics we first need to use `extractPosteriorMeans()` from 
`{SIBER}` to extract posterior estimates of means for each community and group. 

```{r}
mu_post <- extractPosteriorMeans(siber_example, ellipses_posterior)
```

Next we need to use `bayesianLayman()` from `{SIBER}` and use our extracted posterior means to create Bayesian estiamtes for each community metric.  

```{r}
layman_b <- bayesianLayman(mu.post = mu_post)
```

Once we have created our Bayesian estimates for each community metric we can use `extract_layman()` to extract these estimates. We will also create the variable `labels` which will first assign a new name to each community metric and secondly will reorder these names based on how these metrics are often viewed. 

```{r}
layman_bc <- extract_layman(layman_b, community_df = c_names) %>% 
  mutate(
    labels = factor(case_when(
      metric %in% "dX_range" ~ paste0("\U03B4","<sup>", 13, "</sup>",
                                      "C<br>Range"),
      metric %in% "dY_range" ~ paste0("\U03B4","<sup>", 15, "</sup>",
                                      "N<br>Range"),
      metric %in% "TA" ~ "Total Area",
      metric %in% "CD" ~ "Distance to<br>Centroid",
      metric %in% "NND" ~ "Nearest<br>Neighbor<br>Distance",
      metric %in% "SDNND" ~ "SD Nearest<br>Neighbor<br>Distance",
    ),
    levels = c("\U03B4<sup>13</sup>C<br>Range",
               "\U03B4<sup>15</sup>N<br>Range",
               "Total Area",
               "Distance to<br>Centroid",
               "Nearest<br>Neighbor<br>Distance",
               "SD Nearest<br>Neighbor<br>Distance")
    )
  )
```

Prior to using point interval plots we need to create a colour palette that will be used to identify each community.  

```{r}
viridis_colors <- viridis(2, begin = 0.25, end = 0.85,
                          option = "G",
                          alpha = 0.75
)
```

Lastly, we can visualize the distributions of the posterior estimates using `stat_pointinterval()` from {ggdist}. 

```{r}
#| out-width: 100%

ggplot(data = layman_bc, aes(x = labels, 
                             y = post_est, 
                             point_fill = community_name)) + 
  stat_pointinterval(
    point_size = 2.5,
    interval_colour = "grey60",
    position = position_dodge(0.4),
    shape = 21
  ) + 
  scale_fill_manual(name = "Community", 
                    aesthetics = "point_fill",
                    values = viridis_colors) + 
  theme_bw(
    base_size = 15
  ) + 
  theme(
    panel.grid = element_blank(),
    axis.text = element_markdown(),
    legend.position = "inside",
    legend.position.inside = c(0.88, 0.87),
  ) +
  labs(
    x = "Community Metrics",
    y = expression(paste("p(", "‰", "|X)"))
  )
```


